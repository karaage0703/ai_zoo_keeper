{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karaage0703/ai_zoo_keeper/blob/main/ai_zoo_animal_creator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-0mHhP4tpTT"
      },
      "source": [
        "# AI Zoo animal creator\n",
        "\n",
        "Create AI Zoo animal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jUMAVmhVedQ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **Setup**\n",
        "\n",
        "# Setup rembg Reference:\n",
        "# https://stackoverflow.com/questions/71738218/module-pil-has-not-attribute-resampling\n",
        "\n",
        "!pip -qq install diffusers[torch]==0.11.1 transformers\n",
        "!pip -qq install --upgrade --pre triton\n",
        "\n",
        "# install xformers\n",
        "# https://github.com/XavierXiao/Dreambooth-Stable-Diffusion/issues/102\n",
        "# !pip -qq install https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac_various_6/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\n",
        "!pip -qq install https://github.com/metrolobo/xformers_wheels/releases/download/4c06c79_various6/xformers-0.0.15.dev0_4c06c79.d20221201-cp38-cp38-linux_x86_64.whl\n",
        "\n",
        "!pip install -qq tqdm\n",
        "!pip install -qq rembg\n",
        "!pip install -qq pillow==9.2.0\n",
        "\n",
        "import PIL.Image\n",
        "if not hasattr(PIL.Image, 'Resampling'):  # Pillow<9.0\n",
        "    PIL.Image.Resampling = PIL.Image\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from rembg.bg import remove\n",
        "\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "\n",
        "device = \"cuda\"\n",
        "model_id = \"stabilityai/stable-diffusion-2\"\n",
        "\n",
        "if model_id == \"stabilityai/stable-diffusion-2\":\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        model_id, \n",
        "        scheduler=EulerDiscreteScheduler.from_pretrained(\n",
        "        model_id, \n",
        "        subfolder=\"scheduler\"\n",
        "        ), \n",
        "        torch_dtype=torch.float16,\n",
        "        revision=\"fp16\"\n",
        "    ).to(\"cuda\")\n",
        "    pipe.enable_attention_slicing()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Generate Image**\n",
        "#@markdown　Enter Parameter  (Attention: Seed=-1 is random)\n",
        "\n",
        "name = 'karaage' #@param {type:\"string\"}\n",
        "animal = 'kawaii panda' #@param {type:\"string\"}\n",
        "seed_number = -1 #@param\n",
        "\n",
        "num_inference_steps  = 20\n",
        "guidance_scale_value = 7.5\n",
        "width_image = 512\n",
        "height_image = 512\n",
        "\n",
        "def infer(prompt, seed_number, num_inference_steps, guidance_scale_value, width_image, height_image):\n",
        "    generator = torch.Generator(device=device)\n",
        "    latents = None\n",
        "\n",
        "    # Get a new random seed, store it and use it as the generator state\n",
        "    if seed_number < 0:\n",
        "        seed = generator.seed()\n",
        "    else:\n",
        "        seed = seed_number\n",
        "\n",
        "    generator = generator.manual_seed(seed)\n",
        "\n",
        "    image_latent = torch.randn(\n",
        "        (1, pipe.unet.in_channels, height_image // 8, width_image // 8),\n",
        "        generator = generator,\n",
        "        device = device\n",
        "    )\n",
        "\n",
        "    with torch.autocast('cuda'):\n",
        "        image = pipe(\n",
        "            [prompt],\n",
        "            width=width_image,\n",
        "            height=height_image,\n",
        "            guidance_scale=guidance_scale_value,\n",
        "            num_inference_steps=num_inference_steps,\n",
        "            latents = image_latent\n",
        "        ).images[0]\n",
        "\n",
        "    return image, image_latent\n",
        "\n",
        "def draw_image_from_latents(prompt, num_inference_steps, guidance_scale_value, width_image, height_image, image_latent):\n",
        "    with torch.autocast('cuda'):\n",
        "        image = pipe(\n",
        "            [prompt],\n",
        "            width=width_image,\n",
        "            height=height_image,\n",
        "            guidance_scale=guidance_scale_value,\n",
        "            num_inference_steps=num_inference_steps,\n",
        "            latents = image_latent\n",
        "        ).images[0]\n",
        "\n",
        "    return image\n",
        "\n",
        "def draw_image(image):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "image, latents = infer(animal, seed_number, num_inference_steps, guidance_scale_value, width_image, height_image)\n",
        "\n",
        "draw_image(image)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fI7yVL8w58AB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Making variations and save images**\n",
        "#@markdown　Execute for generating images\n",
        "\n",
        "number_frames = 4\n",
        "max_distance = 0.1 #@param {type:\"slider\", min:0.01, max:0.5, step:0.01}\n",
        "random_walk = np.random.default_rng()\n",
        "\n",
        "# random walk in latent space\n",
        "image_cv = []\n",
        "\n",
        "for n in tqdm(range(number_frames)):\n",
        "    for i in range(latents.size()[1]):\n",
        "        for j in range(latents.size()[2]):\n",
        "            for k in range(latents.size()[3]):\n",
        "                latents[0][i][j][k] += random_walk.uniform(-max_distance, max_distance)\n",
        "\n",
        "\n",
        "    image = draw_image_from_latents(animal, num_inference_steps, guidance_scale_value, width_image, height_image, latents)\n",
        "    print('below image is number ' + str(n))\n",
        "    image_np = np.array(image)\n",
        "\n",
        "    image_np = cv2.resize(image_np, dsize=(256, 256))\n",
        "    image_np = remove(image_np)\n",
        "\n",
        "    file_path = os.path.join(f\"{name}_{n:001}.png\")\n",
        "    cv2.imwrite(file_path, image_np)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nVWIYNfzy7qE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Check images**\n",
        "#@markdown　Execute for checking images\n",
        "\n",
        "from IPython.display import Image as IPImage\n",
        "from IPython.display import display_png\n",
        "\n",
        "for n in range(4):\n",
        "  file_path = os.path.join(f\"{name}_{n:001}.png\")\n",
        "  display_png(IPImage(file_path))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_3R0orkk2oy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### download"
      ],
      "metadata": {
        "id": "z0k_dat693Cp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Download images**\n",
        "#@markdown　Execute for downloading images\n",
        "\n",
        "!zip animal.zip *.png\n",
        "\n",
        "from google.colab import files\n",
        "files.download('animal.zip')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gv9J3T6W_yUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submit\n",
        "\n",
        "Submit issue with your animal. \n",
        "\n",
        "https://github.com/karaage0703/ai_zoo_keeper/issues"
      ],
      "metadata": {
        "id": "8xd7w5MUAGyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reference\n"
      ],
      "metadata": {
        "id": "8_ieawWDdpjt"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}